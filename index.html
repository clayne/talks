<!DOCTYPE html><html><head><meta charset="utf-8"><title>Daniel Lemire&#39;s talks</title><link rel="stylesheet" href="styles.css"></head><body><h1>Daniel Lemire&#39;s talks</h1>
<h2>2025</h2><ul>
<li><a href='2025/sea/sea2025.html' title='For decades, Dennard scaling propelled remarkable advancements in processor technology. As transistor sizes shrank, manufacturers increased clock frequencies to enhance computational speed while simultaneously reducing power consumption, adhering to the principle of constant power density. This synergy delivered consistent performance improvements in both hardware and software. However, over the past two decades, this trend has faltered: physical and thermal constraints have caused clock frequencies to plateau, often leaving software performance stagnant as it struggles to fully utilize available hardware capabilities. Nevertheless, modern processors provide substantial opportunities for performance optimization through advanced architectural features. These include enhanced Single-Instruction-Multiple-Data (SIMD) instructions—such as Scalable Vector Extensions (SVE) and AVX-512—which enable parallel processing of large datasets, greater memory-level parallelism to improve data access efficiency, advanced branch predictors to enhance instruction flow, and broader superscalar execution to execute multiple instructions per cycle more effectively. We advocate for a comprehensive approach: robust mathematical models grounded in a current and detailed understanding of system architecture. Through this lens, we explore how algorithmic design can leverage these characteristics of contemporary processors, drawing insights from practical case studies in widely used software. Our findings underscore the critical need to align software design with hardware capabilities to overcome the challenges of the post-Dennard era.'>Algorithms for Modern Processor Architectures</a> <a href='2025/sea/sea2025.pdf' title='For decades, Dennard scaling propelled remarkable advancements in processor technology. As transistor sizes shrank, manufacturers increased clock frequencies to enhance computational speed while simultaneously reducing power consumption, adhering to the principle of constant power density. This synergy delivered consistent performance improvements in both hardware and software. However, over the past two decades, this trend has faltered: physical and thermal constraints have caused clock frequencies to plateau, often leaving software performance stagnant as it struggles to fully utilize available hardware capabilities. Nevertheless, modern processors provide substantial opportunities for performance optimization through advanced architectural features. These include enhanced Single-Instruction-Multiple-Data (SIMD) instructions—such as Scalable Vector Extensions (SVE) and AVX-512—which enable parallel processing of large datasets, greater memory-level parallelism to improve data access efficiency, advanced branch predictors to enhance instruction flow, and broader superscalar execution to execute multiple instructions per cycle more effectively. We advocate for a comprehensive approach: robust mathematical models grounded in a current and detailed understanding of system architecture. Through this lens, we explore how algorithmic design can leverage these characteristics of contemporary processors, drawing insights from practical case studies in widely used software. Our findings underscore the critical need to align software design with hardware capabilities to overcome the challenges of the post-Dennard era.'>PDF</a></li>
</ul>
<h2>2024</h2><ul>
<li><a href='2024/HarveyMuddCollege/HarveyMuddCollege.html' title='Parsing decimal numbers from strings of characters into binary types is a common but relatively expensive task.'>Floating-point number parsing with perfect accuracy at a gigabyte per second</a> <a href='2024/HarveyMuddCollege/HarveyMuddCollege.pdf' title='Parsing decimal numbers from strings of characters into binary types is a common but relatively expensive task.'>PDF</a></li>
</ul>
<h2>2023</h2><ul>
<li><a href='2023/fastfilters/fastfilter.html' title='Conventional Bloom filters provide fast approximate set membership while using little memory. Engineers use them to avoid expensive disk and network accesses. We recently introduced the binary fuse filters that are faster and smaller  at query time while saving at least 30% in memory usage compared to the Bloom filters. The result is an immutable filter, and the construction is slightly slower (e.g., by 50%). We review some performance issues related to our binary fuse filters, but also to  probabilistic filters in general: e.g., how does the query time performance scale with respect to the number of random accesses ? For network transmission, the filters are often compressed: how well do different filters compress ?'>Binary Fuse Filters: Fast and Tiny Immutable Filters</a> <a href='2023/fastfilters/fastfilter.pdf' title='Conventional Bloom filters provide fast approximate set membership while using little memory. Engineers use them to avoid expensive disk and network accesses. We recently introduced the binary fuse filters that are faster and smaller  at query time while saving at least 30% in memory usage compared to the Bloom filters. The result is an immutable filter, and the construction is slightly slower (e.g., by 50%). We review some performance issues related to our binary fuse filters, but also to  probabilistic filters in general: e.g., how does the query time performance scale with respect to the number of random accesses ? For network transmission, the filters are often compressed: how well do different filters compress ?'>PDF</a></li>
<li><a href='2023/performance/performance.html' title='Software is often improved incrementally. Each software optimization should be assessed with microbenchmarks. Unfortunately, there are many pitfalls, such as unrealistic statistical assumptions'>Accurate and efficient software microbenchmarks</a> <a href='2023/performance/performance.pdf' title='Software is often improved incrementally. Each software optimization should be assessed with microbenchmarks. Unfortunately, there are many pitfalls, such as unrealistic statistical assumptions'>PDF</a></li>
<li><a href='2023/url/euro.html' title='With the end of Dennard scaling, the cost of computing is no longer falling at the hardware level: to improve efficiency, we need better software. Competing JavaScript runtimes are sometimes faster than Node.js: can we bridge the gap? We show that Node.js can not only match faster competitors but even surpass them given enough effort. URLs are the most fundamental element in web applications. Node.js 16 was significantly slower than competing engines (Bun and Deno) at URL parsing. By reducing the number of instructions and vectorizing sub-algorithms, we multiplied by three the speed of URL parsing in Node.js (as of Node.js 20). If you have upgraded Node.js, you have the JavaScript engine with the fastest URL parsing in the industry with uncompromising support for the latest WHATGL URL standard. We share our strategies for accelerating both C++ and JavaScript processing in practice.'>Parsing Millions of URLs per Second</a> <a href='2023/url/euro.pdf' title='With the end of Dennard scaling, the cost of computing is no longer falling at the hardware level: to improve efficiency, we need better software. Competing JavaScript runtimes are sometimes faster than Node.js: can we bridge the gap? We show that Node.js can not only match faster competitors but even surpass them given enough effort. URLs are the most fundamental element in web applications. Node.js 16 was significantly slower than competing engines (Bun and Deno) at URL parsing. By reducing the number of instructions and vectorizing sub-algorithms, we multiplied by three the speed of URL parsing in Node.js (as of Node.js 20). If you have upgraded Node.js, you have the JavaScript engine with the fastest URL parsing in the industry with uncompromising support for the latest WHATGL URL standard. We share our strategies for accelerating both C++ and JavaScript processing in practice.'>PDF</a></li>
</ul>
<h2>2021</h2><ul>
<li><a href='2021/spire/spire.html' title='We often represent text using Unicode formats (UTF-8 and UTF-16).  UTF-8 is increasingly popular (XML, HTML, JSON, Rust, Go, Swift, Ruby). UTF-16 is most common in Java, .NET, and inside operating systems such as Windows.'>Unicode at gigabytes per second</a> <a href='2021/spire/spire.pdf' title='We often represent text using Unicode formats (UTF-8 and UTF-16).  UTF-8 is increasingly popular (XML, HTML, JSON, Rust, Go, Swift, Ruby). UTF-16 is most common in Java, .NET, and inside operating systems such as Windows.'>PDF</a></li>
</ul>
</body></html>
