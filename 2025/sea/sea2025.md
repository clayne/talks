---
marp: true
theme: base
title: Algorithms for Modern Processor Architectures
description: Daniel Lemire is a computer science professor at the Data Science Laboratory of the University of Quebec (TELUQ). He is ranked in the top 2% of all scientists (Stanford University/Elsevier ranking, 2024). He is among the 1000 most followed programmers in the world on GitHub; GitHub has over 100 million developers. He published over 85 peer-reviewed research papers. His work is found in many standard libraries (.NET, Rust, GCC/glibc++, LLVM/libc, Go, Node.js, etc.) and in the major Web browsers (Safari, Chrome, etc.). He is an editor at the journal Software: Practice and Experience (Wiley, established in 1971). In 2020, he received the University of Quebecâ€™s 2020 Award of Excellence for Achievement in Research for his work on the acceleration of JSON parsing. His research interests include high-performance programming.
paginate: true
_paginate: false
---



<!-- ![center](simdjsonlogo.png)-->

<!--  --- -->

## <!--fit--> Algorithms for Modern Processor Architectures


Daniel Lemire, professor
UniversitÃ© du QuÃ©bec (TÃ‰LUQ)
MontrÃ©al :canada:

blog: https://lemire.me 
X: [@lemire](https://x.com/lemire)
GitHub: [https://github.com/lemire/](https://github.com/lemire/)

All software for this talk: https://github.com/lemire/talks/tree/master/2025/sea/software

---


# Disk at gigabytes per second

![](fastdisk.png)



---


# Input/Output

- PCI Express 4.0 (2011) : 31.5 GB/s (16 lanes)
- PCI Express 5.0 (2017) : 63 GB/s (16 lanes)
- PCI Express 6.0 (2019) : 128 GB/s (16 lanes)
- PCI Express 7.0 (2022) : 242 GB/s (16 lanes)





---

# High Bandwidth Memory

- Xeon Max processors contain 64 GB of HBM
- Bandwidth 800 GB/s


---


# Some numbers

- Time is discrete: clock cycle
- Processors: 4 GHz ($4 \times 10^9$ cycles per second)
- One cycle is 0.25 nanoseconds
- light: 7.5 centimeters
- One byte per cycle: 4 GB/s

**Easily CPU bound**

---

# Frequencies and transistors

| processor | year  | frequency  | transistors    |
|-----------|-------|------------|----------------|
| Pentium 4 | 2000  | 3.8 GHz    | 0.040 billions | 
| Intel Haswell  | 2013  | 4.4 GHz    | 1.4 billions  | 
| Apple M1  | 2020  | 3.2 GHz    | 16 billions    | 
| Apple M2  | 2022  | 3.49 GHz   | 20 billions    |
| Apple M3  | 2024  | 4.05 GHz   | 25 billions    | 
| Apple M4  | 2024  | 4.5 GHz    | 28 billions    |
| AMD Zen 5 | 2024  | 5.7 GHz    | 50 billions    |


---

![](plots/transistors_vs_years_exponential.png)


---

# Where do the transistors go?

- More cores
- More superscalar execution
- Better speculative execution
- More cache, more memory-level parallelism
- Better data-level parallelism (SIMD)


---

# Superscalar execution

|Â processor       | year    | arithmetic logic units    |
|-----------------|---------|---------------------------|
|Â Pentium 4       |  2000   |    2                      |
|Â AMD Zen 2       |  2019   |    4                      |
|Â AMD Zen 5       |  2024   |    6                      |

---

# Parsing a number


```cpp
double result;
fast_float::from_chars(
  input.data(), input.data() + input.size(), result);
```

---

# Parsing a number of Apple's CPU (M4)

- about 200 instructions
- 7.5 instructions/cycle
- 25 cycles

---

# Deltas (C)

successive difference:

```cpp
    for (size_t i = 1; i < n; ++i) {
        dst[i] = src[i] - src[i - 1];
    }
```


prefix sum:

```cpp
    for (size_t i = 1; i < n; ++i) {
        dst[i] = dst[i - 1] + src[i];
    }
```


---

# Deltas

successive difference (6 instructions): load, sub, add, sub, store, branch


prefix sum (5 instructions): load, sub, add, store, branch

---

# Data dependency analysis

- One data load (multiple cycles of latency)
- Add/substract new value with old
- Store new result (multiple cycles of latency)

---

# Apple M4

| algorithm             | cycles   | instructions   | ins/cycle  |
|-----------------------|----------|----------------|------------|
| successive difference | 1 cycle Â | 6 instructions | 6 instructions/cycle |
| prefix sum | 1 cycle Â | 5 instructions | 5 instructions/cycle |


---

# Pipelining

```
ðŸš‚
```


---

```
ðŸš‚
 ðŸš‚
```


---

```
ðŸš‚
 ðŸš‚
   ðŸš‚
```

---

```
ðŸš‚   + 
 ðŸš‚
   ðŸš‚
    ðŸš‚
```

---

```
ðŸš‚   +ðŸš‰
 ðŸš‚   +
   ðŸš‚
    ðŸš‚
     ðŸš‚
```

---


```
ðŸš‚   +ðŸš‰
 ðŸš‚   +ðŸš‰
  ðŸš‚   +
   ðŸš‚
    ðŸš‚
     ðŸš‚
```

---

```
ðŸš‚   +ðŸš‰
 ðŸš‚   +ðŸš‰
  ðŸš‚   +ðŸš‰
   ðŸš‚   +
    ðŸš‚
     ðŸš‚
      ðŸš‚
```

--- 

# Little's Law

- Latency harms throughput
- Parallelism hides latency

$\mathrm{throughput} = \frac{\mathrm{parallelism}}{\mathrm{latency}}$

---

# Unicode (UTF-16)

- Code points from U+0000 to U+FFFF, a single 16-bit value.
- Beyond: a surrogate pair `[U+D800 to U+DBFF]` followed `U+DC00 to U+DFFF`


---

# Validate 


- Check whether we have a lone code unit ($x \leq \mathrm{0xD7FF} \lor unit\geq \mathrm{0xDBFF}$), if so ok
- Check whether we have the first part of the surrogate ($\mathrm{0xD800} \leq x\leq \mathrm{0xDBFF}$) and if so check that we have the second part of a surrogate

---

# Validate 

```C++
    size_t i = 0;
    for (i < code_units.size()) {
        uint16_t unit = code_units[i];
        if (unit <= 0xD7FF || unit >= 0xE000) { ++i; continue; }
        if (unit >= 0xD800 && unit <= 0xDBFF) {
            if (i + 1 >= code_units.size()) { return false; }
            uint16_t next_unit = code_units[i + 1];
            if (next_unit < 0xDC00 || next_unit > 0xDFFF) { return false; }
            i += 2; // Valid surrogate pair
            continue;
        }
        return false;
    }
```

---

# Performance results (Apple M4)

| input type | cycles | instructions | instructions/cycle |
|------------|--------|--------------|--------------------|
| ASCII      |   1    |     7        |       7            |
| Alternate  |   1    |     8        |       8           |


1 character per second might be just 4 GB/s (slower than disk)

---

# Performance results (Apple M4)

| input type | cycles | instructions | instructions/cycle |
|------------|--------|--------------|--------------------|
| ASCII      |   1    |     7        |       7            |
| Alternate  |   1    |     8        |       8           |
| Random   |   7    |     8        |       1.1          |

We are now under 1 GB/s!

---

# Speculative execution

- Processors *predict* branches
- They execute code *speculatively* (can be wrong!)


---

# How much can your processor learn?

---

# How much can your processor learn?

| size | ns/value | GHz | cycles/value | instr/value | i/c |
|------|---------:|-----:|-------------:|------------:|-----:|
| 1048576 |      1.59 |    4.51 |          7.20 |         8.01 |  1.11 |
| 524288 |      1.50 |    4.51 |          6.76 |         8.01 |  1.19 |
| 262144 |      1.31 |    4.51 |          5.90 |         8.01 |  1.36 |
| 131072 |      0.76 |    4.52 |          3.43 |         8.01 |  2.34 |
|  65536 |      0.49 |    4.52 |          2.20 |         8.01 |  3.64 |
|  32768 |      0.49 |    4.52 |          2.19 |         8.02 |  3.66 |

---

![](plots/size_vs_cycles_english.png)

----

# Finite state machine to the rescue



----

# Speculative execution


---

# Memory-level parallism


---

# Data-level parallelism 

---

# Measurements

https://lemire.me/blog/2023/04/06/are-your-memory-bound-benchmarking-timings-normally-distributed/


https://lemire.me/blog/2023/04/27/hotspot-performance-engineering-fails/

---

# Conclusion